{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4a32ff",
   "metadata": {},
   "source": [
    "# Near-surface max wind speed data wrangle\n",
    "### Takes CSIRO CMIP6 Application-Ready Gridded Climate Data NetCDF daily time series, summarises by health district using population-weighted averaging, and outputs this average as a daily time series for all health districts.\n",
    "\n",
    "#### <i> https://data.csiro.au/collection/csiro:64206 </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a27d0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.agcd_agg_functions' from 'c:\\\\Users\\\\jake.allen.ALLUVIUMQLD\\\\Documents\\\\Repos\\\\climate_health_reference_manual\\\\utils\\\\agcd_agg_functions.py'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import utils.agcd_agg_functions as agg\n",
    "from importlib import reload\n",
    "from shapely.geometry import mapping, box\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.features import geometry_mask\n",
    "import dill\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option('display.max_columns',  None)\n",
    "\n",
    "reload(agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e2477",
   "metadata": {},
   "source": [
    "### Load datasets\n",
    "We load everything into xarray dataset definitions for easy iterations later. Note that no data is being held in memory yet thanks to dask. This only happens once computations are triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44366875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build path dictionary\n",
    "clim_fold = 'E:/Jake_ClimateRasters'\n",
    "\n",
    "def nested_dict():\n",
    "    return defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "path_dict = defaultdict(lambda: defaultdict(nested_dict))\n",
    "\n",
    "models = ['ACCESS-ESM1-5', 'CMCC-ESM2', 'CNRM-ESM2-1', 'EC-Earth3', 'MPI-ESM1-2-HR', 'UKESM1-0-LL']\n",
    "#models = ['ACCESS-CM2']\n",
    "ssps = ['ssp245', 'ssp370']\n",
    "epochs = ['mid', 'late']\n",
    "variables = ['sfcWindmax']\n",
    "\n",
    "# assign model paths\n",
    "for model in models:\n",
    "    for ssp in ssps:\n",
    "        for epoch in epochs:\n",
    "            thisepoch = '2035-2064' if epoch == 'mid' else '2070-2099'\n",
    "            for thisvar in variables:\n",
    "                thispath = Path(f'{clim_fold}/{model}/{ssp}/{thisvar}/AUS-11/{thisepoch}')\n",
    "                ncdfs = []\n",
    "                for path in thispath.rglob('*.nc'):\n",
    "                    ncdfs.append(path)\n",
    "                path_dict[model][ssp][epoch][thisvar] = ncdfs\n",
    "\n",
    "# assign historical observation paths\n",
    "for thisvar in variables:\n",
    "    thispath = Path(f'{clim_fold}/Historical/{thisvar}')\n",
    "    ncdfs = []\n",
    "    for path in thispath.rglob('*.nc'):\n",
    "        ncdfs.append(path)\n",
    "    path_dict['Historical'][thisvar] = ncdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f96153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load districts\n",
    "\n",
    "districts = gpd.read_file('Inputs/health_district_merged.json')\n",
    "\n",
    "#subset districts if necessary\n",
    "#districts = districts[districts['health_district_name'].isin(['Northern NSW', 'Western Sydney', 'Eyre and Far North'])].copy().to_crs('EPSG:4326')\n",
    "\n",
    "# get bounding box\n",
    "minx, miny, maxx, maxy = districts.total_bounds\n",
    "\n",
    "bbox_geom = box(minx, miny, maxx, maxy)\n",
    "bbox = [mapping(bbox_geom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64095051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ncdfs into dictionary for easy wrangling, subsetting to bounding box and chunking by time = 365\n",
    "# use load_var helper function\n",
    "\n",
    "# initialise empty dictionary\n",
    "data_dict = defaultdict(lambda: defaultdict(nested_dict))\n",
    "\n",
    "# load model data\n",
    "for model in models:\n",
    "    for ssp in ssps:\n",
    "        for epoch in epochs:\n",
    "            ds = xr.Dataset({\n",
    "                thisvar: agg.load_var(path_dict[model][ssp][epoch][thisvar], thisvar, bbox)\n",
    "                for thisvar in variables\n",
    "            })\n",
    "            data_dict[model][ssp][epoch] = ds\n",
    "\n",
    "\n",
    "# Load all historical variables into a dict\n",
    "# historical data has misaligned time coordinates, causing issues when combining into a single dataset\n",
    "hist_vars = {}\n",
    "for thisvar in variables:\n",
    "    ds = agg.load_var(path_dict['Historical'][thisvar], thisvar, bbox, chunk=False)\n",
    "\n",
    "    # Force matching time coordinates\n",
    "    if 'time' in hist_vars:\n",
    "        ds['time'] = hist_vars['time']\n",
    "    else:\n",
    "        hist_vars['time'] = ds['time']\n",
    "\n",
    "    hist_vars[thisvar] = ds\n",
    "\n",
    "# Drop the saved 'time' array from the dict\n",
    "hist_vars.pop('time')\n",
    "\n",
    "# Now build the dataset\n",
    "data_dict['Historical'] = xr.Dataset(hist_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d14db",
   "metadata": {},
   "source": [
    "Prepare district polygons (reproject and extract transformation, create column name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a3d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_districts = districts.to_crs(data_dict['Historical']['sfcWindmax'].rio.crs)\n",
    "all_districts['district_name_id'] = all_districts['state'] + '_' +  all_districts['health_district_name']\n",
    "\n",
    "affine = data_dict['Historical']['sfcWindmax'].rio.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a61f77",
   "metadata": {},
   "source": [
    "### Daily maximum windspeed per health district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005915b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for ssp in ssps:\n",
    "        for epoch in epochs:\n",
    "            for thisvar in variables:\n",
    "                # retrieve dataset from dictionary\n",
    "                ds = data_dict[model][ssp][epoch][thisvar]\n",
    "                # create time series dataset using function in agg functions file\n",
    "                df = agg.zonal_maximum_time_series(ds, all_districts, affine, 'district_name_id')\n",
    "\n",
    "                # get time series bounds for filename\n",
    "                period = \"FUTURE2035-2064\" if epoch == 'mid' else \"FUTURE2070-2099\"\n",
    "                \n",
    "                fname = f\"{thisvar}_DailyTimeSeries_52HealthDistricts_{period}_{ssp}_{model}_maximum\"\n",
    "\n",
    "                df.to_csv(f'Outputs/sfcWindmax/{fname}.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical\n",
    "ds = data_dict['Historical']['sfcWindmax']\n",
    "df = agg.zonal_maximum_time_series(ds, all_districts, affine, 'district_name_id')\n",
    "fname = \"sfcWindmax_DailyTimeSeries_52HealthDistricts_CURRENT1985-2014_BARRA-R2_maximum.csv\"\n",
    "df.to_csv(f'Outputs/sfcWindMax/{fname}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7062eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 46.84375 in column 'Western Australia_Pilbara' on date 1996-04-10 12:00:00\n"
     ]
    }
   ],
   "source": [
    "# Drop the date column\n",
    "df_no_date = df.drop(columns='date')\n",
    "\n",
    "# Get the index and column of the max value\n",
    "row_idx, col_name = divmod(df_no_date.values.argmax(), df_no_date.shape[1])\n",
    "\n",
    "# Extract info\n",
    "max_value = df_no_date.iat[row_idx, col_name]\n",
    "max_date = df.loc[row_idx, 'date']\n",
    "max_column = df_no_date.columns[col_name]\n",
    "\n",
    "print(f\"Max value: {max_value} in column '{max_column}' on date {max_date}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
